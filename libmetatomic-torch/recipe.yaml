context:
  version: "0.1.1"
  build_num: 1

package:
  name: libmetatomic-torch
  version: ${{ version | replace('-', '') }}

source:
  url: https://github.com/metatensor/metatomic/releases/download/metatomic-torch-v${{ version }}/metatomic-torch-cxx-${{ version }}.tar.gz
  sha256: 2dc0a0213b7f5df3ac519516f1b17801baa6973d96b339f0b39cadea310fefe1

build:
  number: ${{ build_num }}
  string: h${{ hash }}_${{ build_num }}
  script:
    file: build.nu
    env:
     USE_SCCACHE: ${{ env.get("USE_SCCACHE", default=0) }}


requirements:
  run_exports:
    - ${{ pin_subpackage('libmetatomic-torch', upper_bound='x.x') }}
  build:
    - ${{ compiler('cxx') }}
    - ${{ stdlib("c") }}
    - cmake
    - ninja
    - nushell
    - sccache
  host:
    - libmetatensor >=0.1.14,<0.2
    - libmetatensor-torch >=0.7.5,<0.8
    # We build against the CPU version of torch to not have to deal with CUDA
    # compilers (torch's CMake targets tries to find CUDA compilers even when
    # there is no CUDA code to build). This does not impact the `run`
    # dependency, since libtorch `run_exports` are variant agnostic
    - libtorch * *cpu*

tests:
  - script:
    - if: not win
      then: test -f $PREFIX/lib/libmetatomic_torch$SHLIB_EXT
      else: if not exist %PREFIX%\\Library\\bin\\metatomic_torch.dll exit 1
    - cmake -G Ninja -S test-project -B test-project
    - cmake --build test-project
    - ctest --verbose --output-on-failure --test-dir test-project
    files:
      recipe:
        - test-project/
    requirements:
      run:
        - cmake
        - ninja
        - ${{ compiler('cxx') }}
        - libtorch * *cpu*

about:
  homepage: https://github.com/metatensor/metatomic
  summary: Atomistic machine learning models you can use everywhere for everything
  license: BSD-3-Clause
  license_family: BSD
  license_file:
    - LICENSE
    - _deps/nlohmann_json-src/LICENSE.MIT
  documentation: https://docs.metatensor.org/metatomic/


extra:
  recipe-maintainers:
    - HaoZeke
    - luthaf
